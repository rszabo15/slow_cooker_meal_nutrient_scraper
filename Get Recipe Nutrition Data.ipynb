{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numbers(txt):\n",
    "    \"\"\"\n",
    "    Inputs: string (ex. '10mg.')\n",
    "    Outputs: string with letters and last '.' removed (ex. '10')\n",
    "    \"\"\"\n",
    "    #Remove letters\n",
    "    txt = re.sub('[^0-9\\.]', '', txt)\n",
    "    #Remove '.' at end\n",
    "    if txt[-1] == '.':\n",
    "        txt = txt[:len(txt)-1]\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nutrients(URL):\n",
    "    \"\"\"\n",
    "    Inputs: string of url (Allrecipes url for food recipe)\n",
    "    Outputs: dataframe of nurtitional values if soup object is found\n",
    "    What it Does: Gets html of page, extracts nutritional info, returns in dataframe\n",
    "    \"\"\"\n",
    "    page = requests.get(URL)\n",
    "    if page: \n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        if soup:\n",
    "            #See if class exists in beautiful soup, if not information needed is not on page\n",
    "            try:\n",
    "                txt = soup.find(class_='partial recipe-nutrition-section').find(class_=\"section-body\").text\n",
    "            except:\n",
    "                return pd.DataFrame()\n",
    "            #Clean nutrient output into 'txtf'\n",
    "            txt = txt.strip()\n",
    "            txt = txt.split('\\n')[0]\n",
    "            txtf = txt.split(';')\n",
    "            #extract numbers and nutrients into separate lists (ex. ['fat', 'protein'], [6.2, 3.5])\n",
    "            nums = []\n",
    "            nutrient = []\n",
    "            for val in txtf:\n",
    "                v = val.split()\n",
    "                num = [x for x in v if sum(char.isdigit() for char in x) > 0]\n",
    "                #Clean numbers - remove labels (mg) and '.' if occurs at end\n",
    "                num = [clean_numbers(x) for x in num]\n",
    "                nut = [x.lower() for x in v if sum(char.isdigit() for char in x) == 0]\n",
    "                nums += num\n",
    "                nutrient += nut\n",
    "            #save nutrient data to dataframe for concatenation\n",
    "            d = dict(zip(nutrient, nums))\n",
    "            df = pd.DataFrame(data = [d])\n",
    "            df['url'] = str(URL)\n",
    "            return df\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipe_urls():\n",
    "    \"\"\"\n",
    "    Outputs: list of links to slow cooker recipes from Allrecipes\n",
    "    What it Does: finds all slow cooker recipes from first 20 pages of allrecipes\n",
    "    \"\"\"\n",
    "    all_url = []\n",
    "    #get first 20 pages of slow cooker recipes\n",
    "    url = 'https://www.allrecipes.com/recipes/253/everyday-cooking/slow-cooker/?page={}'\n",
    "    for i in range(20):\n",
    "        url_i = url.format(i+1)\n",
    "        page = requests.get(url_i)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        #Turn soup output into string and regex find all recipe links\n",
    "        t = str(soup)\n",
    "        l = re.findall('(?<=\"url\": \")https:\\/\\/www\\.allrecipes\\.com\\/recipe\\/.*(?=\")', t)\n",
    "        all_url += l\n",
    "    #outputs list of urls with slow cooker recipes\n",
    "    return list(set(all_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_recipe_names(url):\n",
    "    \"\"\"\n",
    "    Inputs: list of urls from dataframe\n",
    "    Outputs: series of recipe name extracted from the url\n",
    "    \"\"\"\n",
    "    recipes = []\n",
    "    for u in url:\n",
    "        #Get indices of '/' and take all chars between last 2 indices\n",
    "        idx = [i for i, ltr in enumerate(str(u))if ltr == '/']\n",
    "        idx.sort(reverse=True)\n",
    "        idx2, idx1 = idx[0], idx[1]\n",
    "        name = str(u)[idx1+1:idx2]\n",
    "        #Clean name by removing '-' and title case\n",
    "        name = name.replace('-', ' ').title()\n",
    "        #append to final list\n",
    "        recipes.append(name)\n",
    "    return recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish dataframe of link, nutrient info\n",
    "df = pd.DataFrame(columns = ['calories', 'carbohydrates', 'cholesterol', 'fat', 'protein', 'sodium', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get recipe URLs\n",
    "url_list = get_recipe_urls()\n",
    "len(url_list) #485 recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 485/485 [05:53<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "#Loop through unique urls and get nutrients and add to df\n",
    "for u in tqdm(url_list):  \n",
    "    #Get nutrients\n",
    "    n = get_nutrients(u)\n",
    "    #Merge nutrient data with df\n",
    "    df = pd.concat([df, n],ignore_index = True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe</th>\n",
       "      <th>calories</th>\n",
       "      <th>carbohydrates_g</th>\n",
       "      <th>cholesterol_mg</th>\n",
       "      <th>fat_g</th>\n",
       "      <th>protein_g</th>\n",
       "      <th>sodium_mg</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slow Cooker Creamed Corn Just Like Rudys Bbq</td>\n",
       "      <td>354</td>\n",
       "      <td>26.1</td>\n",
       "      <td>86.8</td>\n",
       "      <td>27.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>243.4</td>\n",
       "      <td>https://www.allrecipes.com/recipe/234375/slow-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Slow Cooker Salsa Chicken</td>\n",
       "      <td>148</td>\n",
       "      <td>7.5</td>\n",
       "      <td>58.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>23.1</td>\n",
       "      <td>539.7</td>\n",
       "      <td>https://www.allrecipes.com/recipe/236128/slow-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Randys Slow Cooker Ravioli Lasagna</td>\n",
       "      <td>544</td>\n",
       "      <td>52.9</td>\n",
       "      <td>91.3</td>\n",
       "      <td>23.6</td>\n",
       "      <td>29.4</td>\n",
       "      <td>1333.8</td>\n",
       "      <td>https://www.allrecipes.com/recipe/234397/randy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Warm Mexican Corn Dip</td>\n",
       "      <td>138</td>\n",
       "      <td>6.2</td>\n",
       "      <td>35</td>\n",
       "      <td>12.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>272.9</td>\n",
       "      <td>https://www.allrecipes.com/recipe/107512/warm-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alisons Slow Cooker Vegetable Beef Soup</td>\n",
       "      <td>228</td>\n",
       "      <td>21.2</td>\n",
       "      <td>37.7</td>\n",
       "      <td>9.9</td>\n",
       "      <td>15.4</td>\n",
       "      <td>1716.8</td>\n",
       "      <td>https://www.allrecipes.com/recipe/26354/alison...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         recipe calories carbohydrates_g  \\\n",
       "0  Slow Cooker Creamed Corn Just Like Rudys Bbq      354            26.1   \n",
       "1                     Slow Cooker Salsa Chicken      148             7.5   \n",
       "2            Randys Slow Cooker Ravioli Lasagna      544            52.9   \n",
       "3                         Warm Mexican Corn Dip      138             6.2   \n",
       "4       Alisons Slow Cooker Vegetable Beef Soup      228            21.2   \n",
       "\n",
       "  cholesterol_mg fat_g protein_g sodium_mg  \\\n",
       "0           86.8  27.3       5.9     243.4   \n",
       "1           58.5   2.4      23.1     539.7   \n",
       "2           91.3  23.6      29.4    1333.8   \n",
       "3             35  12.3       2.1     272.9   \n",
       "4           37.7   9.9      15.4    1716.8   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.allrecipes.com/recipe/234375/slow-...  \n",
       "1  https://www.allrecipes.com/recipe/236128/slow-...  \n",
       "2  https://www.allrecipes.com/recipe/234397/randy...  \n",
       "3  https://www.allrecipes.com/recipe/107512/warm-...  \n",
       "4  https://www.allrecipes.com/recipe/26354/alison...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename df columns to include units for nutrients\n",
    "df.columns = ['calories', 'carbohydrates_g', 'cholesterol_mg', 'fat_g', 'protein_g', 'sodium_mg', 'url']\n",
    "#Convert url to string\n",
    "df['recipe'] = add_recipe_names(df.url)\n",
    "#Reorder columns\n",
    "df = df[['recipe', 'calories', 'carbohydrates_g', 'cholesterol_mg', 'fat_g', 'protein_g', 'sodium_mg', 'url']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save df to csv\n",
    "df.to_csv('recipe_nutrients.csv', index=False)\n",
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
